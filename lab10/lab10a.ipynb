{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"lab10a_empty.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KDMeojC4XA9R"},"source":["## Training a word2vec model from scratch\n","\n","-- Prof. Dorien Herremans\n","\n","We will start by training a word2vec model from scratch using the gensim library. You will need to ensure that you have gensim installed, and a file decompressor to load our dataset. \n","\n","Note: these models may take a while to train. Be sure to switch the runtime of  Google Colab to us a TPU or GPU hardware accellerator (in the menu at the top). \n","\n","Let's start by installing some libraries that we will use:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mDkvVQRXu8rj","outputId":"8df20022-a303-413a-9722-5aa9b5a77cac","executionInfo":{"status":"ok","timestamp":1573726184662,"user_tz":-480,"elapsed":10096,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["!pip install gensim\n","!pip install wget"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n","Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.4)\n","Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.2)\n","Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.10.14)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.9.11)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n","Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.13.14)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n","Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n","Collecting wget\n","  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=fd0c28687f88293541f32f70ab1e1a7293fd19efe13a5890fd592f7353413a82\n","  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0qiQjAboxcBN"},"source":["Now we can import these libraries:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"f5wZmGH0XHYP","colab":{}},"source":["# imports needed \n","import gensim \n","import wget\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"02-XoaTBYuY1"},"source":["We will train our model using a very small dataset for demonstrative purposes. Note that for a real data science project you should train on a much larger dataset. \n","\n","We will use the complete works of Shakespeare. You can find the file at https://dorienherremans.com/drop/CDS/CNNs/shakespeare.txt"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1Tg9GZzYt4nf","outputId":"20654cf2-3023-477c-f758-585097916b4c","executionInfo":{"status":"ok","timestamp":1573729402901,"user_tz":-480,"elapsed":3625,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# download the dataset\n","!wget \"https://dorienherremans.com/drop/CDS/CNNs/shakespeare.txt\"\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["--2019-11-14 11:03:20--  https://dorienherremans.com/drop/CDS/CNNs/shakespeare.txt\n","Resolving dorienherremans.com (dorienherremans.com)... 96.127.180.74\n","Connecting to dorienherremans.com (dorienherremans.com)|96.127.180.74|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5447743 (5.2M) [text/plain]\n","Saving to: ‘shakespeare.txt.1’\n","\n","\rshakespeare.txt.1     0%[                    ]       0  --.-KB/s               \rshakespeare.txt.1   100%[===================>]   5.20M  --.-KB/s    in 0.1s    \n","\n","2019-11-14 11:03:20 (46.5 MB/s) - ‘shakespeare.txt.1’ saved [5447743/5447743]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VBrRXv0NZyRM","colab_type":"code","outputId":"5b9f225a-e166-46df-d211-ac9bfc91f754","executionInfo":{"status":"error","timestamp":1573726580952,"user_tz":-480,"elapsed":70671,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":333}},"source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","#necessary imports:\n","link = 'https://drive.google.com/open?id=13SD25ui9HMXvqD9pcw0_qZ8K1Qq1OfxE' # The shareable link of metadata file\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('shakespeare.txt')  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-3bf6559a416c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdownloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shakespeare.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shakespeare.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"nKHwTYP3YpJZ"},"source":["Let's read the input file and convert each line into a list of words (tokenizing). Do do this, we create a function read_input which is called in the penultimate line below: "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F8J2jQ1JYpJd","outputId":"ab19675a-45cc-4501-db04-21f0b435e4db","executionInfo":{"status":"ok","timestamp":1573729411573,"user_tz":-480,"elapsed":5907,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["def read_input(input_file):\n","    print(\"reading file...\")\n","    with open (input_file, 'r') as f: lines = f.readlines()\n","    for line in lines:\n","    # do some pre-processing and return a (tokenized) list      # of words for each review text\n","    # you can print the output here to understand  # the preprocessing (tokenizing)\n","        yield  gensim.utils.simple_preprocess  (line)\n","    # each review item new becomes a series of words # this is a list of lists\n","\n","# point to the location on your filesystem\n","data_file  =  'shakespeare.txt'\n","\n","documents = list (read_input (data_file)) \n","print(\"Done reading data file\")"],"execution_count":21,"outputs":[{"output_type":"stream","text":["reading file...\n","Done reading data file\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZnDX2S9eX1Ub"},"source":["Now let's train the word2vec model using our document variable (which is a list of word lists). Note that you can specify a number of hyperparameters below:\n","* min_count removes all words that occur less then min_count\n","* window: window size in the skip-gram\n","* workers: how many threads to use\n","* size: number of dimension of your new word embedding vector (typically 100-200). Smaller datasets require a smaller number\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VJWmrzCRZm9Z","outputId":"b174fe7f-92a8-4407-de94-cb8563c61305","executionInfo":{"status":"ok","timestamp":1573729447840,"user_tz":-480,"elapsed":32419,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","model  =  gensim.models.Word2Vec  (documents,  size=150,  window=5,  min_count=2,  workers=4) \n","model.train(documents,total_examples=len(documents),epochs=10)\n"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6704015, 8675160)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0hKwagKCYpJ7"},"source":["That's it! Now you've trained the model! \n","\n","Now let's explore some properties of our new word space. You can get the words most close (read:  most similar) to a given word. Remember, the only texts the model has seen is shakespeare!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MTGeHhiaZzIU","outputId":"8b14cf4b-6c06-470d-dd76-606d19290193","executionInfo":{"status":"ok","timestamp":1573726719646,"user_tz":-480,"elapsed":842,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["w1 = \"king\"\n","model.wv.most_similar  (positive=w1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('prince', 0.6431804895401001),\n"," ('plantagenets', 0.5619862675666809),\n"," ('dauphin', 0.5495572686195374),\n"," ('warwick', 0.5464417338371277),\n"," ('fifth', 0.5446635484695435),\n"," ('duke', 0.5242741703987122),\n"," ('sixth', 0.5195103883743286),\n"," ('ghost', 0.5169710516929626),\n"," ('crown', 0.5003525614738464),\n"," ('emperor', 0.4984578490257263)]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GuJhHUOve1km","outputId":"8472e6b5-883b-481f-bcb3-3b5724a2d831","executionInfo":{"status":"ok","timestamp":1573726739932,"user_tz":-480,"elapsed":848,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["# look up top 6 words similar to 'smile'\n","w1 = [\"smile\"]\n","model.wv.most_similar  (positive=w1,topn=6)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('laugh', 0.7505191564559937),\n"," ('tremble', 0.6889244914054871),\n"," ('rail', 0.6800838112831116),\n"," ('blush', 0.6739107966423035),\n"," ('push', 0.671941876411438),\n"," ('spit', 0.6716383099555969)]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iZu3GGf9e41V","outputId":"359c74f0-ce58-4d5d-bd28-38b2e556411e","executionInfo":{"status":"ok","timestamp":1573726759390,"user_tz":-480,"elapsed":724,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["# look up top 6 words similar to 'france'\n","w1 = [\"france\"]\n","model.wv.most_similar  (positive=w1,topn=6)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('england', 0.6466440558433533),\n"," ('orleans', 0.5653001070022583),\n"," ('princess', 0.5530722737312317),\n"," ('realm', 0.5522609353065491),\n"," ('wales', 0.5495685338973999),\n"," ('egypt', 0.5465847253799438)]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VlDIzGHZe9yN","outputId":"4c88828f-0687-4fe1-f8e5-ec7400fdc12a","executionInfo":{"status":"ok","timestamp":1573726782411,"user_tz":-480,"elapsed":779,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["# look up top 6 words similar to 'sword'\n","w1 = [\"sword\"]\n","model.wv.most_similar  (positive=w1,topn=6)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('head', 0.7913775444030762),\n"," ('knife', 0.720653772354126),\n"," ('finger', 0.7087414264678955),\n"," ('throat', 0.701163649559021),\n"," ('pocket', 0.6948661804199219),\n"," ('body', 0.6912802457809448)]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wvKKzFHbfAnr","outputId":"60e34af3-7b1c-4b98-b00d-91c4fe096fdc","executionInfo":{"status":"ok","timestamp":1573726799095,"user_tz":-480,"elapsed":741,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":241}},"source":["# get everything related to stuff on the royalty and not related to farmer\n","w1  =  [\"king\",'queen','prince'] \n","w2  =  ['farmer']\n","model.wv.most_similar  (positive=w1,negative=w2,topn=10)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('princess', 0.6012568473815918),\n"," ('warwick', 0.5922337770462036),\n"," ('duke', 0.5894880890846252),\n"," ('ghost', 0.5376821160316467),\n"," ('dauphin', 0.5213593244552612),\n"," ('comfort', 0.5193885564804077),\n"," ('emperor', 0.5070196390151978),\n"," ('moor', 0.5068163275718689),\n"," ('duchess', 0.5065346956253052),\n"," ('gods', 0.49567297101020813)]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TkQZ1KkiYpK_"},"source":["Explore the similarity (e.g. distance) between two words. Does it make sense?"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3nFv31TxfBMX","outputId":"5c6e9bfb-43b3-4a48-ec96-80a72b2d0dc2","executionInfo":{"status":"ok","timestamp":1573726812719,"user_tz":-480,"elapsed":639,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["# similarity between two similar words\n","model.wv.similarity(w1=\"pretty\",w2=\"beautiful\")\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.5057323"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0PXLoSftYpLO","outputId":"36bfa72b-18fc-49e1-c112-c0a93a753547","executionInfo":{"status":"ok","timestamp":1573726824088,"user_tz":-480,"elapsed":783,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["# similarity between two opposing words\n","model.wv.similarity(w1=\"king\",w2=\"farmer\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["-0.027320124"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hpftKgByYpLT"},"source":["Try some other combinations :) "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Nw7Aabx4YpLU"},"source":["We can even use it to perform more 'smart' assigments: "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8eO7ra-efKYq","outputId":"87e9f58c-1d2a-4e8d-90d4-9795f54da0ac","executionInfo":{"status":"ok","timestamp":1573726837560,"user_tz":-480,"elapsed":754,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# Which one is the odd one out in this list?\n","model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n","/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if np.issubdtype(vec.dtype, np.int):\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'france'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ll3RsRN2YpL3"},"source":["If you are interested in plotting the words in a multidimensional space, you can actually get the vector coordinates of each word: "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rEOzUfKcYpL4","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"1_U5DgEPYpMI"},"source":["## Bonus: visualising our model in t-SNE: "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0g6g7s-MYpMK","outputId":"f8d1b6ee-cdf3-49d4-a236-9b9686b43cab","executionInfo":{"status":"error","timestamp":1573726858696,"user_tz":-480,"elapsed":1234,"user":{"displayName":"gao yunyi","photoUrl":"","userId":"11459245605115543358"}},"colab":{"base_uri":"https://localhost:8080/","height":316}},"source":["from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def tsne_plot(model):\n","    \"Creates and TSNE model and plots it\"\n","\n","    labels = []\n","    tokens = []\n","    \n","    count = 0\n","    for word in model.wv.vocab:\n","        # to speed up the process, let's limit to the first 100 elements\n","        if count < 100:\n","            # TODO get the labels\n","            count = count+1\n","\n","    # set the t-sne values\n","    # TODO fit the t-sne model\n","\n","    x = []\n","    y = []\n","    for value in new_values:\n","        x.append(value[0])\n","        y.append(value[1])\n","        \n","    plt.figure(figsize=(16, 16)) \n","    for i in range(len(x)):\n","        plt.scatter(x[i],y[i])\n","        plt.annotate(labels[i],\n","                     xy=(x[i], y[i]),\n","                     xytext=(5, 2),\n","                     textcoords='offset points',\n","                     ha='right',\n","                     va='bottom')\n","    plt.show()\n","    \n","tsne_plot(model)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-fa17f8707ecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtsne_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-18-fa17f8707ecf>\u001b[0m in \u001b[0;36mtsne_plot\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'new_values' is not defined"]}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UsRf6k4wYpMd"},"source":["## References\n","\n","* https://radimrehurek.com/gensim/models/word2vec.html\n","* https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n","* https://github.com/kavgan/nlp-text-mining-working-examples/tree/master/word2vec\n","* https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5"]}]}